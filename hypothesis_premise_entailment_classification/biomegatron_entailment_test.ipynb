{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d54f89-71ed-4d69-990b-1f3512a982b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9639aeb-4ac3-4c82-8821-e67fac34de57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>evidences</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women suffering from both claustrophobia and I...</td>\n",
       "      <td>[\"Exclusion Criteria:\", \"  History of bilatera...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are no conditions on mental mental healt...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"  Women 18 years\", \" ...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the secondary trial requires patients to be ov...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"  Patients presenting...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patients currently taking part in the secondar...</td>\n",
       "      <td>[\"  Participation in another clinical trial wi...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HER2 + Patients in the primary trial receive t...</td>\n",
       "      <td>[\"INTERVENTION 1: \", \"  Trastuzumab\", \"  Parti...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>alcoholic patients are excluded from the prima...</td>\n",
       "      <td>[\"  Be non-smokers (no nicotine use within the...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Patients with a histologically/cytologically c...</td>\n",
       "      <td>[\"  Non-small cell lung cancer\", \"  Small cell...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>the primary trial treats one of its patient co...</td>\n",
       "      <td>[\"INTERVENTION 1: \", \"  Pregabalin150\", \"  Pat...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>after a month of TAK-228 Plus Tamoxifen treatm...</td>\n",
       "      <td>[\"Outcome Measurement: \", \"  Ki67 Expression\",...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Patients with a history of severe anaphylactic...</td>\n",
       "      <td>[\"  History of grade 3 or 4 allergic reactions...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hypothesis  \\\n",
       "0    Women suffering from both claustrophobia and I...   \n",
       "1    There are no conditions on mental mental healt...   \n",
       "2    the secondary trial requires patients to be ov...   \n",
       "3    Patients currently taking part in the secondar...   \n",
       "4    HER2 + Patients in the primary trial receive t...   \n",
       "..                                                 ...   \n",
       "495  alcoholic patients are excluded from the prima...   \n",
       "496  Patients with a histologically/cytologically c...   \n",
       "497  the primary trial treats one of its patient co...   \n",
       "498  after a month of TAK-228 Plus Tamoxifen treatm...   \n",
       "499  Patients with a history of severe anaphylactic...   \n",
       "\n",
       "                                             evidences          label  \n",
       "0    [\"Exclusion Criteria:\", \"  History of bilatera...  Contradiction  \n",
       "1    [\"Inclusion Criteria:\", \"  Women 18 years\", \" ...     Entailment  \n",
       "2    [\"Inclusion Criteria:\", \"  Patients presenting...     Entailment  \n",
       "3    [\"  Participation in another clinical trial wi...     Entailment  \n",
       "4    [\"INTERVENTION 1: \", \"  Trastuzumab\", \"  Parti...  Contradiction  \n",
       "..                                                 ...            ...  \n",
       "495  [\"  Be non-smokers (no nicotine use within the...  Contradiction  \n",
       "496  [\"  Non-small cell lung cancer\", \"  Small cell...     Entailment  \n",
       "497  [\"INTERVENTION 1: \", \"  Pregabalin150\", \"  Pat...     Entailment  \n",
       "498  [\"Outcome Measurement: \", \"  Ki67 Expression\",...  Contradiction  \n",
       "499  [\"  History of grade 3 or 4 allergic reactions...  Contradiction  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.read_csv('./output/test_hypothesis_evidences.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212df86b-c0f6-4965-bca5-ad4966cf78e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d8b363-c68c-4562-bb3d-8770d7c8f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis_lst=test_df['hypothesis'].values.tolist()\n",
    "len(hypothesis_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8efe8157-ae5d-41c2-834b-27b33b160b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_lst=test_df['evidences'].apply(lambda l:' '.join(json.loads(l))).values.tolist()\n",
    "len(evidence_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8414a700-6dce-4600-bf9e-348083904d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id={\"Contradiction\":0,\"Entailment\":1}\n",
    "label_lst=test_df['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "len(label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc36c52-1423-46cf-a7ca-2e024248c536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b616df7-cc19-42fe-8d96-21a98ebe369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizer, MegatronBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55163bb8-916d-474d-a970-418a7415fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MegatronBertForSequenceClassification were not initialized from the model checkpoint at ../transformer_models/biomegatron345uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# text_tok=AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "# text_clf=AutoModelForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)\n",
    "#roberta-base\n",
    "# text_tok=AutoTokenizer.from_pretrained('roberta-base')\n",
    "# text_clf=AutoModelForSequenceClassification.from_pretrained('roberta-base',num_labels=2)\n",
    "#bio-bert\n",
    "# text_tok=AutoTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
    "# text_clf=AutoModelForSequenceClassification.from_pretrained('dmis-lab/biobert-v1.1',num_labels=2)\n",
    "#biomegatron\n",
    "text_tok=BertTokenizer.from_pretrained('../transformer_models/biomegatron345uncased')\n",
    "text_clf=MegatronBertForSequenceClassification.from_pretrained('../transformer_models/biomegatron345uncased',num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73236413-f29a-4f46-b22e-2fd86a9232e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975670e9-455c-4dd2-87b3-59b53c19514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputSequence:\n",
    "    \n",
    "    def __init__(self,tok,l_text,l_text2,l_label,batch_size=64,gpu=True):\n",
    "        \n",
    "        self.data_len=len(l_text)\n",
    "        self.data_idx=[i for i in range(self.data_len)]\n",
    "        self.texts=tok(l_text,l_text2,padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "        self.l_label=np.array(l_label)\n",
    "        print('tokenize done')\n",
    "        \n",
    "        self.batch_size=batch_size\n",
    "        self.gpu=gpu\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.data_idx)\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        start=i*self.batch_size\n",
    "        batch_idx=self.data_idx[start:min(start+self.batch_size,self.data_len)]\n",
    "        \n",
    "        return_texts=dict([(k,self.texts[k][batch_idx]) for k in self.texts])\n",
    "        return_labels=torch.from_numpy(\n",
    "            self.l_label[batch_idx].astype(np.int64)\n",
    "        )\n",
    "        \n",
    "        if self.gpu:\n",
    "            return_texts=dict([(k,return_texts[k].cuda()) for k in return_texts])\n",
    "            return_labels=return_labels.cuda()\n",
    "        \n",
    "        return return_texts,return_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(1.0*self.data_len/self.batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900de28-95f2-4e4b-8a54-cbc530d83edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d69c714-4ee8-4189-8236-644d83ad93ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize done\n"
     ]
    }
   ],
   "source": [
    "testing_data=InputSequence(text_tok,hypothesis_lst,evidence_lst,label_lst,batch_size=16,gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84262558-9f7d-40f1-b67d-ad91ddf809da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MegatronBertForSequenceClassification were not initialized from the model checkpoint at ../transformer_models/biomegatron345uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ./output/clf_models/biomegatron345uncased_epoch_00009.pt batch: 31\r"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "# model_names=['bert-base-uncased']+[\n",
    "#     './output/clf_models/bert-base-uncased_epoch_{}.pt'.format(format(epoch,'05d'))\n",
    "#     for epoch in range(10)\n",
    "# ]\n",
    "#roberta-base\n",
    "# model_names=['roberta-base']+[\n",
    "#     './output/clf_models/roberta-base_epoch_{}.pt'.format(format(epoch,'05d'))\n",
    "#     for epoch in range(10)\n",
    "# ]\n",
    "#biobert\n",
    "# model_names=['dmis-lab/biobert-v1.1']+[\n",
    "#     './output/clf_models/biobert-v1.1_epoch_{}.pt'.format(format(epoch,'05d'))\n",
    "#     for epoch in range(10)\n",
    "# ]\n",
    "#biomegatron\n",
    "model_names=['../transformer_models/biomegatron345uncased']+[\n",
    "    './output/clf_models/biomegatron345uncased_epoch_{}.pt'.format(format(epoch,'05d'))\n",
    "    for epoch in range(10)\n",
    "]\n",
    "for model_name in model_names:\n",
    "    scores.append([])\n",
    "    clf=MegatronBertForSequenceClassification.from_pretrained(model_name).cuda()\n",
    "    with torch.no_grad():\n",
    "        for batch in range(len(testing_data)):\n",
    "            batch_texts,batch_labels=testing_data[batch]\n",
    "            scores[-1].append(F.softmax(clf(**batch_texts).logits,dim=1).detach().cpu().numpy())\n",
    "            print('model:',model_name,'batch:',batch,end='\\r')\n",
    "    scores[-1]=np.concatenate(scores[-1],axis=0)\n",
    "    clf.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e35e51be-bc41-4165-9499-f813c31d65bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>AVG_PREC</th>\n",
       "      <th>F1</th>\n",
       "      <th>PREC</th>\n",
       "      <th>REC</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.519633</td>\n",
       "      <td>0.211838</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.539815</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.594687</td>\n",
       "      <td>0.413613</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.587879</td>\n",
       "      <td>0.601036</td>\n",
       "      <td>0.528875</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.600983</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.600179</td>\n",
       "      <td>0.568507</td>\n",
       "      <td>0.581590</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.622298</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.635232</td>\n",
       "      <td>0.454308</td>\n",
       "      <td>0.654135</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.612131</td>\n",
       "      <td>0.570842</td>\n",
       "      <td>0.586498</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.629284</td>\n",
       "      <td>0.553097</td>\n",
       "      <td>0.618812</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.616986</td>\n",
       "      <td>0.595668</td>\n",
       "      <td>0.542763</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         epoch  AVG_PREC        F1      PREC    REC    ACC\n",
       "0   pretrained  0.519633  0.211838  0.478873  0.136  0.494\n",
       "1            1  0.539815  0.298246  0.554348  0.204  0.520\n",
       "2            2  0.594687  0.413613  0.598485  0.316  0.552\n",
       "3            3  0.587879  0.601036  0.528875  0.696  0.538\n",
       "4            4  0.600983  0.480769  0.602410  0.400  0.568\n",
       "5            5  0.600179  0.568507  0.581590  0.556  0.578\n",
       "6            6  0.622298  0.580645  0.585366  0.576  0.584\n",
       "7            7  0.635232  0.454308  0.654135  0.348  0.582\n",
       "8            8  0.612131  0.570842  0.586498  0.556  0.582\n",
       "9            9  0.629284  0.553097  0.618812  0.500  0.596\n",
       "10          10  0.616986  0.595668  0.542763  0.660  0.552"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score,f1_score,precision_score,recall_score,accuracy_score\n",
    "\n",
    "y_true=label_lst\n",
    "results=[]\n",
    "for epoch in range(len(scores)):\n",
    "    y_prob=scores[epoch][:,1]\n",
    "    y_pred=[1 if a>0.5 else 0 for a in y_prob]\n",
    "    results.append([\n",
    "        'pretrained' if epoch==0 else epoch,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(results,columns=['epoch','AVG_PREC','F1','PREC','REC','ACC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8265fd-2878-420e-866f-6761190fba30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
