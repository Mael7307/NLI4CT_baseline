{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score,f1_score,precision_score,recall_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencetype_df=[]\n",
    "sectiontype_df=[]\n",
    "type_df=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id={\"Contradiction\":0,\"Entailment\":1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>section</th>\n",
       "      <th>label</th>\n",
       "      <th>InferenceType</th>\n",
       "      <th>SectionType</th>\n",
       "      <th>Type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women suffering from both claustrophobia and I...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"Women are eligible to...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>NLI</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.105403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are no conditions on mental mental healt...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"Women 18 years\", \"His...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>NLI</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.051436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the secondary trial requires patients to be ov...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"Patients presenting f...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>NLI</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.056703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patients currently taking part in the secondar...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"Be a female of any ra...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>NLI</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.089784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HER2 + Patients in the primary trial receive t...</td>\n",
       "      <td>[\"INTERVENTION 1:\", \"Trastuzumab\", \"Participan...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.121693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>alcoholic patients are excluded from the prima...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"All participants will...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.054109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Patients with a histologically/cytologically c...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"Voluntarily signed an...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>NLI</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.128692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>the primary trial treats one of its patient co...</td>\n",
       "      <td>[\"INTERVENTION 1:\", \"Pregabalin150\", \"Patients...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.192566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>after a month of TAK-228 Plus Tamoxifen treatm...</td>\n",
       "      <td>[\"Outcome Measurement:\", \"Ki67 Expression\", \"K...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>Results</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.315865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Patients with a history of severe anaphylactic...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"Patients must have hi...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>NLI</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.251028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             statement  \\\n",
       "0    Women suffering from both claustrophobia and I...   \n",
       "1    There are no conditions on mental mental healt...   \n",
       "2    the secondary trial requires patients to be ov...   \n",
       "3    Patients currently taking part in the secondar...   \n",
       "4    HER2 + Patients in the primary trial receive t...   \n",
       "..                                                 ...   \n",
       "495  alcoholic patients are excluded from the prima...   \n",
       "496  Patients with a histologically/cytologically c...   \n",
       "497  the primary trial treats one of its patient co...   \n",
       "498  after a month of TAK-228 Plus Tamoxifen treatm...   \n",
       "499  Patients with a history of severe anaphylactic...   \n",
       "\n",
       "                                               section          label  \\\n",
       "0    [\"Inclusion Criteria:\", \"Women are eligible to...  Contradiction   \n",
       "1    [\"Inclusion Criteria:\", \"Women 18 years\", \"His...     Entailment   \n",
       "2    [\"Inclusion Criteria:\", \"Patients presenting f...     Entailment   \n",
       "3    [\"Inclusion Criteria:\", \"Be a female of any ra...     Entailment   \n",
       "4    [\"INTERVENTION 1:\", \"Trastuzumab\", \"Participan...  Contradiction   \n",
       "..                                                 ...            ...   \n",
       "495  [\"Inclusion Criteria:\", \"All participants will...  Contradiction   \n",
       "496  [\"Inclusion Criteria:\", \"Voluntarily signed an...     Entailment   \n",
       "497  [\"INTERVENTION 1:\", \"Pregabalin150\", \"Patients...     Entailment   \n",
       "498  [\"Outcome Measurement:\", \"Ki67 Expression\", \"K...  Contradiction   \n",
       "499  [\"Inclusion Criteria:\", \"Patients must have hi...  Contradiction   \n",
       "\n",
       "    InferenceType   SectionType        Type     score  \n",
       "0             NLI   Eligibility  Comparison  0.105403  \n",
       "1             NLI   Eligibility      Single  0.051436  \n",
       "2             NLI   Eligibility  Comparison  0.056703  \n",
       "3             NLI   Eligibility  Comparison  0.089784  \n",
       "4       Numerical  Intervention  Comparison  0.121693  \n",
       "..            ...           ...         ...       ...  \n",
       "495     Numerical   Eligibility  Comparison  0.054109  \n",
       "496           NLI   Eligibility      Single  0.128692  \n",
       "497     Numerical  Intervention  Comparison  0.192566  \n",
       "498     Numerical       Results      Single  0.315865  \n",
       "499           NLI   Eligibility      Single  0.251028  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BM25\n",
    "model_name='BM25'\n",
    "df=pd.read_csv('../output/categorized_bm25_score.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NLI', 'Numerical', 'Neither'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['InferenceType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Eligibility', 'Intervention', 'Adverse Events', 'Results'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SectionType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Comparison', 'Single'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thre=0.1\n",
    "for t in ['NLI','Numerical']:\n",
    "    y_true=df[df.InferenceType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.InferenceType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    inferencetype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.1\n",
    "for t in ['Eligibility', 'Intervention', 'Adverse Events', 'Results']:\n",
    "    y_true=df[df.SectionType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.SectionType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    sectiontype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.1\n",
    "for t in ['Comparison', 'Single']:\n",
    "    y_true=df[df.Type==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.Type==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    type_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT-base-uncased\n",
    "model_name='BERT-base-uncased'\n",
    "df=pd.read_csv('../output/categorized_bert-base-uncased_score.csv')\n",
    "\n",
    "thre=0.5\n",
    "for t in ['NLI','Numerical']:\n",
    "    y_true=df[df.InferenceType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.InferenceType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    inferencetype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Eligibility', 'Intervention', 'Adverse Events', 'Results']:\n",
    "    y_true=df[df.SectionType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.SectionType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    sectiontype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Comparison', 'Single']:\n",
    "    y_true=df[df.Type==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.Type==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    type_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RoBERTa-base\n",
    "model_name='roberta-base'\n",
    "df=pd.read_csv('../output/categorized_roberta-base_score.csv')\n",
    "\n",
    "thre=0.5\n",
    "for t in ['NLI','Numerical']:\n",
    "    y_true=df[df.InferenceType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.InferenceType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    inferencetype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Eligibility', 'Intervention', 'Adverse Events', 'Results']:\n",
    "    y_true=df[df.SectionType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.SectionType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    sectiontype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Comparison', 'Single']:\n",
    "    y_true=df[df.Type==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.Type==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    type_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biobert-v1.1\n",
    "model_name='biobert-v1.1'\n",
    "df=pd.read_csv('../output/categorized_biobert-v1.1_score.csv')\n",
    "\n",
    "thre=0.5\n",
    "for t in ['NLI','Numerical']:\n",
    "    y_true=df[df.InferenceType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.InferenceType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    inferencetype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Eligibility', 'Intervention', 'Adverse Events', 'Results']:\n",
    "    y_true=df[df.SectionType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.SectionType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    sectiontype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Comparison', 'Single']:\n",
    "    y_true=df[df.Type==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.Type==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    type_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biomegatron345uncased\n",
    "model_name='biomegatron345uncased'\n",
    "df=pd.read_csv('../output/categorized_biomegatron345uncased_score.csv')\n",
    "\n",
    "thre=0.5\n",
    "for t in ['NLI','Numerical']:\n",
    "    y_true=df[df.InferenceType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.InferenceType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    inferencetype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Eligibility', 'Intervention', 'Adverse Events', 'Results']:\n",
    "    y_true=df[df.SectionType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.SectionType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    sectiontype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Comparison', 'Single']:\n",
    "    y_true=df[df.Type==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.Type==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    type_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt2\n",
    "model_name='gpt2'\n",
    "df=pd.read_csv('../output/categorized_gpt2_score.csv')\n",
    "\n",
    "thre=0.5\n",
    "for t in ['NLI','Numerical']:\n",
    "    y_true=df[df.InferenceType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.InferenceType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    inferencetype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Eligibility', 'Intervention', 'Adverse Events', 'Results']:\n",
    "    y_true=df[df.SectionType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.SectionType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    sectiontype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Comparison', 'Single']:\n",
    "    y_true=df[df.Type==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.Type==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    type_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t5-base\n",
    "model_name='t5-base'\n",
    "df=pd.read_csv('../output/categorized_t5-base_score.csv')\n",
    "\n",
    "thre=0.5\n",
    "for t in ['NLI','Numerical']:\n",
    "    y_true=df[df.InferenceType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.InferenceType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    inferencetype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Eligibility', 'Intervention', 'Adverse Events', 'Results']:\n",
    "    y_true=df[df.SectionType==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.SectionType==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    sectiontype_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "thre=0.5\n",
    "for t in ['Comparison', 'Single']:\n",
    "    y_true=df[df.Type==t]['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "    y_prob=df[df.Type==t]['score'].values.tolist()\n",
    "    y_pred=[1 if a>thre else 0 for a in y_prob]\n",
    "    type_df.append([\n",
    "        model_name,t,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>AVG_PREC</th>\n",
       "      <th>F1</th>\n",
       "      <th>PREC</th>\n",
       "      <th>REC</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>NLI</td>\n",
       "      <td>0.590450</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.460784</td>\n",
       "      <td>0.457627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BERT-base-uncased</td>\n",
       "      <td>NLI</td>\n",
       "      <td>0.634589</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>NLI</td>\n",
       "      <td>0.776780</td>\n",
       "      <td>0.676329</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.621469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biobert-v1.1</td>\n",
       "      <td>NLI</td>\n",
       "      <td>0.736885</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.638418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>biomegatron345uncased</td>\n",
       "      <td>NLI</td>\n",
       "      <td>0.668426</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.615819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>NLI</td>\n",
       "      <td>0.523174</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.502825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>NLI</td>\n",
       "      <td>0.598432</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.548023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>0.425100</td>\n",
       "      <td>0.467797</td>\n",
       "      <td>0.413174</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.452962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BERT-base-uncased</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>0.469614</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.526132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>0.555344</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.595819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>biobert-v1.1</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>0.577539</td>\n",
       "      <td>0.587814</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.599303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>biomegatron345uncased</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>0.583717</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.541353</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.592334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>0.455024</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.458763</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.498258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>0.435082</td>\n",
       "      <td>0.429119</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.480836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model       type  AVG_PREC        F1      PREC       REC  \\\n",
       "0                    BM25        NLI  0.590450  0.494737  0.534091  0.460784   \n",
       "2       BERT-base-uncased        NLI  0.634589  0.663793  0.592308  0.754902   \n",
       "4            roberta-base        NLI  0.776780  0.676329  0.666667  0.686275   \n",
       "6            biobert-v1.1        NLI  0.736885  0.686275  0.686275  0.686275   \n",
       "8   biomegatron345uncased        NLI  0.668426  0.660000  0.673469  0.647059   \n",
       "10                   gpt2        NLI  0.523174  0.576923  0.566038  0.588235   \n",
       "12                t5-base        NLI  0.598432  0.595960  0.614583  0.578431   \n",
       "1                    BM25  Numerical  0.425100  0.467797  0.413174  0.539062   \n",
       "3       BERT-base-uncased  Numerical  0.469614  0.492537  0.471429  0.515625   \n",
       "5            roberta-base  Numerical  0.555344  0.462963  0.568182  0.390625   \n",
       "7            biobert-v1.1  Numerical  0.577539  0.587814  0.543046  0.640625   \n",
       "9   biomegatron345uncased  Numerical  0.583717  0.551724  0.541353  0.562500   \n",
       "11                   gpt2  Numerical  0.455024  0.552795  0.458763  0.695312   \n",
       "13                t5-base  Numerical  0.435082  0.429119  0.421053  0.437500   \n",
       "\n",
       "         ACC  \n",
       "0   0.457627  \n",
       "2   0.559322  \n",
       "4   0.621469  \n",
       "6   0.638418  \n",
       "8   0.615819  \n",
       "10  0.502825  \n",
       "12  0.548023  \n",
       "1   0.452962  \n",
       "3   0.526132  \n",
       "5   0.595819  \n",
       "7   0.599303  \n",
       "9   0.592334  \n",
       "11  0.498258  \n",
       "13  0.480836  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(inferencetype_df,columns=['model','type','AVG_PREC','F1','PREC','REC','ACC']).sort_values('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>AVG_PREC</th>\n",
       "      <th>F1</th>\n",
       "      <th>PREC</th>\n",
       "      <th>REC</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>biobert-v1.1</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0.747301</td>\n",
       "      <td>0.619469</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.641667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0.453748</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0.513182</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BERT-base-uncased</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0.597176</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>biomegatron345uncased</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0.705018</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Adverse Events</td>\n",
       "      <td>0.722204</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0.501102</td>\n",
       "      <td>0.490066</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>biobert-v1.1</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0.650059</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.628788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0.639767</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.621212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BERT-base-uncased</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0.535888</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0.507805</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0.483062</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.492424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>biomegatron345uncased</td>\n",
       "      <td>Eligibility</td>\n",
       "      <td>0.584374</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.553030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biomegatron345uncased</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.639157</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.654930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.497715</td>\n",
       "      <td>0.523490</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.503572</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.507042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>biobert-v1.1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.676132</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.671455</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BERT-base-uncased</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.582049</td>\n",
       "      <td>0.546763</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.556338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.459272</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.436620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Results</td>\n",
       "      <td>0.661578</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.556604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>biomegatron345uncased</td>\n",
       "      <td>Results</td>\n",
       "      <td>0.623401</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BERT-base-uncased</td>\n",
       "      <td>Results</td>\n",
       "      <td>0.548118</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Results</td>\n",
       "      <td>0.480421</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.518868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25</td>\n",
       "      <td>Results</td>\n",
       "      <td>0.543599</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>biobert-v1.1</td>\n",
       "      <td>Results</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.575472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>Results</td>\n",
       "      <td>0.490959</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.481132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model            type  AVG_PREC        F1      PREC  \\\n",
       "14           biobert-v1.1  Adverse Events  0.747301  0.619469  0.660377   \n",
       "2                    BM25  Adverse Events  0.453748  0.157895  0.375000   \n",
       "26                t5-base  Adverse Events  0.513182  0.504348  0.527273   \n",
       "22                   gpt2  Adverse Events  0.475273  0.615385  0.500000   \n",
       "6       BERT-base-uncased  Adverse Events  0.597176  0.648649  0.545455   \n",
       "18  biomegatron345uncased  Adverse Events  0.705018  0.661017  0.672414   \n",
       "10           roberta-base  Adverse Events  0.722204  0.666667  0.666667   \n",
       "0                    BM25     Eligibility  0.501102  0.490066  0.435294   \n",
       "12           biobert-v1.1     Eligibility  0.650059  0.666667  0.604938   \n",
       "8            roberta-base     Eligibility  0.639767  0.609375  0.629032   \n",
       "4       BERT-base-uncased     Eligibility  0.535888  0.554054  0.500000   \n",
       "24                t5-base     Eligibility  0.507805  0.515152  0.515152   \n",
       "20                   gpt2     Eligibility  0.483062  0.531469  0.493506   \n",
       "16  biomegatron345uncased     Eligibility  0.584374  0.575540  0.547945   \n",
       "17  biomegatron345uncased    Intervention  0.639157  0.625954  0.683333   \n",
       "21                   gpt2    Intervention  0.497715  0.523490  0.500000   \n",
       "25                t5-base    Intervention  0.503572  0.500000  0.507246   \n",
       "13           biobert-v1.1    Intervention  0.676132  0.588235  0.615385   \n",
       "9            roberta-base    Intervention  0.671455  0.523810  0.600000   \n",
       "5       BERT-base-uncased    Intervention  0.582049  0.546763  0.558824   \n",
       "1                    BM25    Intervention  0.459272  0.529412  0.454545   \n",
       "11           roberta-base         Results  0.661578  0.459770  0.588235   \n",
       "19  biomegatron345uncased         Results  0.623401  0.528302  0.528302   \n",
       "7       BERT-base-uncased         Results  0.548118  0.537037  0.527273   \n",
       "23                   gpt2         Results  0.480421  0.598425  0.513514   \n",
       "3                    BM25         Results  0.543599  0.573770  0.507246   \n",
       "15           biobert-v1.1         Results  0.614754  0.628099  0.558824   \n",
       "27                t5-base         Results  0.490959  0.455446  0.479167   \n",
       "\n",
       "         REC       ACC  \n",
       "14  0.583333  0.641667  \n",
       "2   0.100000  0.466667  \n",
       "26  0.483333  0.525000  \n",
       "22  0.800000  0.500000  \n",
       "6   0.800000  0.566667  \n",
       "18  0.650000  0.666667  \n",
       "10  0.666667  0.666667  \n",
       "0   0.560606  0.416667  \n",
       "12  0.742424  0.628788  \n",
       "8   0.590909  0.621212  \n",
       "4   0.621212  0.500000  \n",
       "24  0.515152  0.515152  \n",
       "20  0.575758  0.492424  \n",
       "16  0.606061  0.553030  \n",
       "17  0.577465  0.654930  \n",
       "21  0.549296  0.500000  \n",
       "25  0.492958  0.507042  \n",
       "13  0.563380  0.605634  \n",
       "9   0.464789  0.577465  \n",
       "5   0.535211  0.556338  \n",
       "1   0.633803  0.436620  \n",
       "11  0.377358  0.556604  \n",
       "19  0.528302  0.528302  \n",
       "7   0.547170  0.528302  \n",
       "23  0.716981  0.518868  \n",
       "3   0.660377  0.509434  \n",
       "15  0.716981  0.575472  \n",
       "27  0.433962  0.481132  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sectiontype_df,columns=['model','type','AVG_PREC','F1','PREC','REC','ACC']).sort_values('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>AVG_PREC</th>\n",
       "      <th>F1</th>\n",
       "      <th>PREC</th>\n",
       "      <th>REC</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.472631</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.414815</td>\n",
       "      <td>0.453875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BERT-base-uncased</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.545599</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.523985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.654866</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.626087</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.608856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biobert-v1.1</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.665383</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>0.614815</td>\n",
       "      <td>0.623616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>biomegatron345uncased</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.581146</td>\n",
       "      <td>0.550607</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.590406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.488470</td>\n",
       "      <td>0.550336</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>0.505535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>0.506769</td>\n",
       "      <td>0.527076</td>\n",
       "      <td>0.514085</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.516605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.478226</td>\n",
       "      <td>0.517375</td>\n",
       "      <td>0.465278</td>\n",
       "      <td>0.582609</td>\n",
       "      <td>0.454148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BERT-base-uncased</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.577527</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.554622</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>0.554585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.699469</td>\n",
       "      <td>0.568720</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.602620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>biobert-v1.1</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.634538</td>\n",
       "      <td>0.589552</td>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.602620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>biomegatron345uncased</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.678439</td>\n",
       "      <td>0.647773</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.620087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.468749</td>\n",
       "      <td>0.584838</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.704348</td>\n",
       "      <td>0.497817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.501272</td>\n",
       "      <td>0.454976</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.417391</td>\n",
       "      <td>0.497817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model        type  AVG_PREC        F1      PREC       REC  \\\n",
       "0                    BM25  Comparison  0.472631  0.430769  0.448000  0.414815   \n",
       "2       BERT-base-uncased  Comparison  0.545599  0.582524  0.517241  0.666667   \n",
       "4            roberta-base  Comparison  0.654866  0.576000  0.626087  0.533333   \n",
       "6            biobert-v1.1  Comparison  0.665383  0.619403  0.624060  0.614815   \n",
       "8   biomegatron345uncased  Comparison  0.581146  0.550607  0.607143  0.503704   \n",
       "10                   gpt2  Comparison  0.488470  0.550336  0.503067  0.607407   \n",
       "12                t5-base  Comparison  0.506769  0.527076  0.514085  0.540741   \n",
       "1                    BM25      Single  0.478226  0.517375  0.465278  0.582609   \n",
       "3       BERT-base-uncased      Single  0.577527  0.564103  0.554622  0.573913   \n",
       "5            roberta-base      Single  0.699469  0.568720  0.625000  0.521739   \n",
       "7            biobert-v1.1      Single  0.650980  0.634538  0.589552  0.686957   \n",
       "9   biomegatron345uncased      Single  0.678439  0.647773  0.606061  0.695652   \n",
       "11                   gpt2      Single  0.468749  0.584838  0.500000  0.704348   \n",
       "13                t5-base      Single  0.501272  0.454976  0.500000  0.417391   \n",
       "\n",
       "         ACC  \n",
       "0   0.453875  \n",
       "2   0.523985  \n",
       "4   0.608856  \n",
       "6   0.623616  \n",
       "8   0.590406  \n",
       "10  0.505535  \n",
       "12  0.516605  \n",
       "1   0.454148  \n",
       "3   0.554585  \n",
       "5   0.602620  \n",
       "7   0.602620  \n",
       "9   0.620087  \n",
       "11  0.497817  \n",
       "13  0.497817  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(type_df,columns=['model','type','AVG_PREC','F1','PREC','REC','ACC']).sort_values('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
