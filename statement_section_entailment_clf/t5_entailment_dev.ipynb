{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d54f89-71ed-4d69-990b-1f3512a982b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9639aeb-4ac3-4c82-8821-e67fac34de57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>section</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there is a 13.2% difference between the result...</td>\n",
       "      <td>[\"Outcome Measurement:\", \"Event-free Survival\"...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patients with significantly elevated ejection ...</td>\n",
       "      <td>[\"Inclusion criteria:\", \"Inclusion Criteria:\",...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a significant number of the participants in th...</td>\n",
       "      <td>[\"Adverse Events 1:\", \"Total: 20/167 (11.98%)\"...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the primary trial does not report the PFS or o...</td>\n",
       "      <td>[\"Outcome Measurement:\", \"Local Control Using ...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prior treatment with fulvestrant or with a pho...</td>\n",
       "      <td>[\"Inclusion Criteria:\", \"Postmenopausal women ...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>The the primary trial intervention involves on...</td>\n",
       "      <td>[\"INTERVENTION 1:\", \"Letrozole\", \"Participants...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>the secondary trial reported 1 single case of ...</td>\n",
       "      <td>[\"Adverse Events 1:\", \"Total: 16/48 (33.33%)\",...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>the secondary trial and the primary trial do n...</td>\n",
       "      <td>[\"Outcome Measurement:\", \"Number of Patients W...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>the outcome measurement of the primary trial i...</td>\n",
       "      <td>[\"Outcome Measurement:\", \"Progression-free Sur...</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>All the primary trial patients had a minimum o...</td>\n",
       "      <td>[\"Outcome Measurement:\", \"Complete Response + ...</td>\n",
       "      <td>Contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             statement  \\\n",
       "0    there is a 13.2% difference between the result...   \n",
       "1    Patients with significantly elevated ejection ...   \n",
       "2    a significant number of the participants in th...   \n",
       "3    the primary trial does not report the PFS or o...   \n",
       "4    Prior treatment with fulvestrant or with a pho...   \n",
       "..                                                 ...   \n",
       "195  The the primary trial intervention involves on...   \n",
       "196  the secondary trial reported 1 single case of ...   \n",
       "197  the secondary trial and the primary trial do n...   \n",
       "198  the outcome measurement of the primary trial i...   \n",
       "199  All the primary trial patients had a minimum o...   \n",
       "\n",
       "                                               section          label  \n",
       "0    [\"Outcome Measurement:\", \"Event-free Survival\"...  Contradiction  \n",
       "1    [\"Inclusion criteria:\", \"Inclusion Criteria:\",...  Contradiction  \n",
       "2    [\"Adverse Events 1:\", \"Total: 20/167 (11.98%)\"...  Contradiction  \n",
       "3    [\"Outcome Measurement:\", \"Local Control Using ...     Entailment  \n",
       "4    [\"Inclusion Criteria:\", \"Postmenopausal women ...  Contradiction  \n",
       "..                                                 ...            ...  \n",
       "195  [\"INTERVENTION 1:\", \"Letrozole\", \"Participants...  Contradiction  \n",
       "196  [\"Adverse Events 1:\", \"Total: 16/48 (33.33%)\",...     Entailment  \n",
       "197  [\"Outcome Measurement:\", \"Number of Patients W...     Entailment  \n",
       "198  [\"Outcome Measurement:\", \"Progression-free Sur...     Entailment  \n",
       "199  [\"Outcome Measurement:\", \"Complete Response + ...  Contradiction  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df=pd.read_csv('./output/dev_statement_section.csv')\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212df86b-c0f6-4965-bca5-ad4966cf78e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d8b363-c68c-4562-bb3d-8770d7c8f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis_lst=dev_df['statement'].values.tolist()\n",
    "len(hypothesis_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8efe8157-ae5d-41c2-834b-27b33b160b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_lst=dev_df['section'].apply(lambda l:' '.join(json.loads(l))).values.tolist()\n",
    "len(evidence_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8414a700-6dce-4600-bf9e-348083904d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id={\"Contradiction\":0,\"Entailment\":1}\n",
    "label_lst=dev_df['label'].apply(lambda x:label2id[x]).values.tolist()\n",
    "len(label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc36c52-1423-46cf-a7ca-2e024248c536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b616df7-cc19-42fe-8d96-21a98ebe369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x20779zz/.local/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "text_tok = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "text_clf = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73236413-f29a-4f46-b22e-2fd86a9232e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "975670e9-455c-4dd2-87b3-59b53c19514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputSequence:\n",
    "    \n",
    "    def __init__(self,tok,l_text,l_text2,l_label,batch_size=64,gpu=True,task_prefix = \"Detect entailment: \"):\n",
    "        \n",
    "        self.data_len=len(l_text)\n",
    "        self.data_idx=[i for i in range(self.data_len)]\n",
    "        self.texts=tok([task_prefix+' '.join([a,b]) for a,b in zip(l_text,l_text2)],\n",
    "                       padding=\"longest\",\n",
    "                       max_length=512,#max_source_length,\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\",\n",
    "                      )\n",
    "        self.labels=tok([\"Entailment\" if lab==1 else \"Contradiction\" for lab in l_label],\n",
    "                         padding=\"longest\",\n",
    "                         max_length=128,#,\n",
    "                         truncation=True,\n",
    "                         return_tensors=\"pt\",\n",
    "                        )\n",
    "        print('tokenize done')\n",
    "        \n",
    "        self.batch_size=batch_size\n",
    "        self.gpu=gpu\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.data_idx)\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        start=i*self.batch_size\n",
    "        batch_idx=self.data_idx[start:min(start+self.batch_size,self.data_len)]\n",
    "        \n",
    "        return_texts=dict([(k,self.texts[k][batch_idx]) for k in self.texts])\n",
    "        return_labels=dict([(k,self.labels[k][batch_idx]) for k in self.labels])\n",
    "        \n",
    "        if self.gpu:\n",
    "            return_texts=dict([(k,return_texts[k].cuda()) for k in return_texts])\n",
    "            return_labels=dict([(k,return_labels[k].cuda()) for k in return_labels])\n",
    "        \n",
    "        return return_texts,return_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(1.0*self.data_len/self.batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900de28-95f2-4e4b-8a54-cbc530d83edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d69c714-4ee8-4189-8236-644d83ad93ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize done\n"
     ]
    }
   ],
   "source": [
    "testing_data=InputSequence(text_tok,hypothesis_lst,evidence_lst,label_lst,batch_size=16,gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84262558-9f7d-40f1-b67d-ad91ddf809da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x20779zz/.local/lib/python3.9/site-packages/transformers/generation_utils.py:1227: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "2022-12-09 18:05:35.439208: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: t5-base batch: 0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x20779zz/.local/lib/python3.9/site-packages/transformers/generation_utils.py:1227: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ./output/clf_models/t5-base_epoch_00009.pt batch: 12\r"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "#T5\n",
    "model_names=['t5-base']+[\n",
    "    './output/clf_models/t5-base_epoch_{}.pt'.format(format(epoch,'05d'))\n",
    "    for epoch in range(10)\n",
    "]\n",
    "for model_name in model_names:\n",
    "    scores.append([])\n",
    "    clf=T5ForConditionalGeneration.from_pretrained(model_name).cuda()\n",
    "    with torch.no_grad():\n",
    "        for batch in range(len(testing_data)):\n",
    "            batch_texts,batch_labels=testing_data[batch]\n",
    "            output_texts=text_tok.batch_decode(\n",
    "                clf.generate(\n",
    "                    input_ids=batch_texts[\"input_ids\"],\n",
    "                    attention_mask=batch_texts[\"attention_mask\"],\n",
    "                    do_sample=False,  # disable sampling to test if batching affects output\n",
    "                ),\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "            # print(output_texts)\n",
    "            scores[-1].append([[0.0,1.0] if t=='Entailment' else [1.0,0.0] for t in output_texts])\n",
    "            print('model:',model_name,'batch:',batch,end='\\r')\n",
    "    scores[-1]=np.concatenate(scores[-1],axis=0)\n",
    "    clf.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35e51be-bc41-4165-9499-f813c31d65bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x20779zz/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>AVG_PREC</th>\n",
       "      <th>F1</th>\n",
       "      <th>PREC</th>\n",
       "      <th>REC</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.497518</td>\n",
       "      <td>0.580913</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.486154</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.492881</td>\n",
       "      <td>0.352201</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.331034</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.495119</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.502536</td>\n",
       "      <td>0.414201</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.518737</td>\n",
       "      <td>0.532663</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.502544</td>\n",
       "      <td>0.369427</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         epoch  AVG_PREC        F1      PREC   REC    ACC\n",
       "0   pretrained  0.500000  0.000000  0.000000  0.00  0.500\n",
       "1            1  0.497518  0.580913  0.496454  0.70  0.495\n",
       "2            2  0.486154  0.404494  0.461538  0.36  0.470\n",
       "3            3  0.500000  0.621212  0.500000  0.82  0.500\n",
       "4            4  0.500000  0.603175  0.500000  0.76  0.500\n",
       "5            5  0.492881  0.352201  0.474576  0.28  0.485\n",
       "6            6  0.508000  0.331034  0.533333  0.24  0.515\n",
       "7            7  0.495119  0.445652  0.488095  0.41  0.490\n",
       "8            8  0.502536  0.414201  0.507246  0.35  0.505\n",
       "9            9  0.518737  0.532663  0.535354  0.53  0.535\n",
       "10          10  0.502544  0.369427  0.508772  0.29  0.505"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score,f1_score,precision_score,recall_score,accuracy_score\n",
    "\n",
    "y_true=label_lst\n",
    "results=[]\n",
    "for epoch in range(len(scores)):\n",
    "    y_prob=scores[epoch][:,1]\n",
    "    y_pred=[1 if a>0.5 else 0 for a in y_prob]\n",
    "    results.append([\n",
    "        'pretrained' if epoch==0 else epoch,\n",
    "        average_precision_score(y_true,y_prob),\n",
    "        f1_score(y_true,y_pred),\n",
    "        precision_score(y_true,y_pred),\n",
    "        recall_score(y_true,y_pred),\n",
    "        accuracy_score(y_true,y_pred)\n",
    "    ])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(results,columns=['epoch','AVG_PREC','F1','PREC','REC','ACC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfac0f4-f95f-457b-a1d5-9fe62f944d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34c616bf-27b5-46fa-b718-cfc0411f9982",
   "metadata": {},
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "# use different length sentences to test batching\n",
    "sentences = [\"The house is wonderful.\", \"I like to work in NYC.\"]\n",
    "\n",
    "inputs = tokenizer([task_prefix + sentence for sentence in sentences], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output_sequences = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    do_sample=False,  # disable sampling to test if batching affects output\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(output_sequences, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
